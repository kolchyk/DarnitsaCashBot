#!/usr/bin/env python3
"""–¢–µ—Å—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ OCR –Ω–∞ Heroku —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ check.jpg.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∏–º–∏—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ Heroku:
1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤–º–µ—Å—Ç–æ storage - –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª)
2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
3. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Tesseract
4. –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
5. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/test_heroku_ocr.py
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from services.ocr_worker.preprocess import preprocess_image, UnreadableImageError
from services.ocr_worker.tesseract_runner import TesseractRunner, TesseractRuntimeError
from services.ocr_worker.postprocess import build_structured_payload
from libs.common.config import AppSettings
from libs.data.repositories import CatalogRepository
from libs.data import async_session_factory


def print_section(title: str, char: str = "="):
    """–ü–µ—á–∞—Ç–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏."""
    print("\n" + char * 80)
    print(f"  {title}")
    print(char * 80)


def print_dict(data: dict, indent: int = 0):
    """–ü–µ—á–∞—Ç–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    for key, value in data.items():
        if isinstance(value, dict):
            print(" " * indent + f"{key}:")
            print_dict(value, indent + 2)
        elif isinstance(value, list):
            print(" " * indent + f"{key}: [{len(value)} items]")
            if value and isinstance(value[0], dict):
                for i, item in enumerate(value[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —ç–ª–µ–º–µ–Ω—Ç–∞
                    print(" " * (indent + 2) + f"[{i}]:")
                    print_dict(item, indent + 4)
                if len(value) > 3:
                    print(" " * (indent + 2) + f"... –∏ –µ—â–µ {len(value) - 3} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        else:
            print(" " * indent + f"{key}: {value}")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OCR."""
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
    os.environ.setdefault("TELEGRAM_BOT_TOKEN", "dummy")
    os.environ.setdefault("ENCRYPTION_SECRET", "dummy_secret")
    
    settings = AppSettings()
    
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —á–µ–∫–∞
    check_file = project_root / "check.jpg"
    
    if not check_file.exists():
        print(f"‚ùå –§–∞–π–ª {check_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return 1
    
    print_section("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–ï–•–ê–ù–ò–ó–ú–ê OCR –ù–ê HEROKU", "=")
    print(f"üìÑ –§–∞–π–ª: {check_file}")
    print(f"üìÖ –í—Ä–µ–º—è: {datetime.now().isoformat()}")
    
    # –®–∞–≥ 1: –ß—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print_section("–®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    try:
        with open(check_file, "rb") as f:
            image_bytes = f.read()
        print(f"‚úÖ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(image_bytes):,} –±–∞–π—Ç ({len(image_bytes) / 1024:.2f} KB)")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return 1
    
    # –®–∞–≥ 2: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print_section("–®–∞–≥ 2: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    try:
        preprocess_result = preprocess_image(image_bytes, save_intermediates=False)
        print("‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        print("\nüìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print_dict(preprocess_result.metadata, indent=2)
    except UnreadableImageError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ—á–∏—Ç–∞–µ–º–æ - {e}")
        return 1
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # –®–∞–≥ 3: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Tesseract
    print_section("–®–∞–≥ 3: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (Tesseract OCR)")
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π —è–∑—ã–∫ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        settings.ocr_languages = "ukr"
        runner = TesseractRunner(settings)
        print(f"‚úÖ Tesseract –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"   - –Ø–∑—ã–∫–∏: {settings.ocr_languages} (—Ç–æ–ª—å–∫–æ —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π)")
        print(f"   - TESSDATA_PREFIX: {os.environ.get('TESSDATA_PREFIX', '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω')}")
        
        tesseract_result = runner.run(preprocess_result)
        print("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ—Ñ–∏–ª—è–º:")
        for profile_name, tokens in tesseract_result.tokens_by_profile.items():
            stats = tesseract_result.stats.get(profile_name, {})
            print(f"\n  –ü—Ä–æ—Ñ–∏–ª—å '{profile_name}':")
            print(f"    - –¢–æ–∫–µ–Ω–æ–≤: {stats.get('token_count', 0)}")
            print(f"    - –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats.get('mean_confidence', 0):.2%}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤
            if tokens:
                sample_text = " ".join(token.text for token in tokens[:10])
                print(f"    - –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {sample_text[:100]}...")
    except TesseractRuntimeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Tesseract: {e}")
        import traceback
        traceback.print_exc()
        return 1
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # –®–∞–≥ 4: –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print_section("–®–∞–≥ 4: –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã (–¥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
    from services.ocr_worker.postprocess import cluster_tokens_by_line
    line_clusters_original = cluster_tokens_by_line(tesseract_result.tokens_by_profile.get("line_items", []))
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ –ë–î (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        catalog_aliases = {}
        try:
            async with async_session_factory() as session:
                catalog_repo = CatalogRepository(session)
                catalog = await catalog_repo.list_active()
                catalog_aliases = {
                    item.sku_code: [alias.lower() for alias in item.product_aliases] 
                    for item in catalog
                }
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –∫–∞—Ç–∞–ª–æ–≥: {len(catalog_aliases)} SKU")
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ –ë–î: {e}")
            print("   –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∫–∞—Ç–∞–ª–æ–≥–∞...")
        
        structured_payload = build_structured_payload(
            preprocess_metadata=preprocess_result.metadata,
            tesseract_stats=tesseract_result.stats,
            tokens_by_profile=tesseract_result.tokens_by_profile,
            catalog_aliases=catalog_aliases,
            settings=settings,
        )
        print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # –®–∞–≥ 5: –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print_section("–®–∞–≥ 5: –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò", "=")
    
    print("\nüìã –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
    print(f"  - –¢–æ—Ä–≥–æ–≤–µ—Ü: {structured_payload.get('merchant', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}")
    print(f"  - –î–∞—Ç–∞ –ø–æ–∫—É–ø–∫–∏: {structured_payload.get('purchase_ts', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}")
    print(f"  - –û–±—â–∞—è —Å—É–º–º–∞: {structured_payload.get('total', 0) / 100 if structured_payload.get('total') else 0:.2f} –≥—Ä–Ω")
    
    print(f"\nüì¶ –¢–û–í–ê–†–´ ({len(structured_payload.get('line_items', []))}):")
    line_items = structured_payload.get('line_items', [])
    # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º
    original_texts = {}
    if 'line_clusters_original' in locals():
        for i, cluster in enumerate(line_clusters_original):
            if i < len(line_items):
                original_texts[i] = cluster.text
    
    for i, item in enumerate(line_items, 1):
        price_uah = item.get('price', 0) / 100 if item.get('price') else 0
        quantity = item.get('quantity', 1)
        confidence = item.get('confidence', 0)
        sku_code = item.get('sku_code')
        sku_score = item.get('sku_match_score', 0)
        
        normalized_name = item.get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        original_name = original_texts.get(i-1, normalized_name)
        
        print(f"\n  {i}. {normalized_name}")
        if original_name != normalized_name and any(ord(c) > 127 for c in original_name):
            print(f"     (–æ—Ä–∏–≥–∏–Ω–∞–ª: {original_name})")
        print(f"     –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {quantity}")
        print(f"     –¶–µ–Ω–∞: {price_uah:.2f} –≥—Ä–Ω")
        print(f"     –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")
        if sku_code:
            print(f"     SKU: {sku_code} (—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {sku_score:.2%})")
    
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –£–í–ï–†–ï–ù–ù–û–°–¢–ò:")
    confidence_data = structured_payload.get('confidence', {})
    print(f"  - –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence_data.get('mean', 0):.2%}")
    print(f"  - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: {confidence_data.get('min', 0):.2%}")
    print(f"  - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: {confidence_data.get('max', 0):.2%}")
    print(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: {confidence_data.get('token_count', 0)}")
    print(f"  - –ö–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞ –∞–≤—Ç–æ-–ø—Ä–∏–Ω—è—Ç–∏–µ: {confidence_data.get('auto_accept_candidate', False)}")
    
    print("\n‚ö†Ô∏è  –ê–ù–û–ú–ê–õ–ò–ò:")
    anomalies = structured_payload.get('anomalies', [])
    if anomalies:
        for anomaly in anomalies:
            print(f"  - {anomaly}")
    else:
        print("  ‚úÖ –ê–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    print(f"\nüîç –¢–†–ï–ë–£–ï–¢–°–Ø –†–£–ß–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: {structured_payload.get('manual_review_required', False)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–ª–æ–≤–∞ "–î–∞—Ä–Ω–∏—Ü—è"
    print_section("–ü–†–û–í–ï–†–ö–ê –ù–ê–õ–ò–ß–ò–Ø –ü–†–ï–ü–ê–†–ê–¢–û–í '–î–∞—Ä–Ω–∏—Ü—è'")
    # –£—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ unidecode
    search_terms_cyrillic = ["–¥–∞—Ä–Ω–∏—Ü—è", "–¥–∞—Ä–Ω–∏—Ü–∞", "–¥–∞—Ä–Ω–∏—Ü—ñ", "–¥–∞—Ä–Ω–∏—Ü—é", "–¥–∞—Ä–Ω–∏—Ü–µ—é"]
    search_terms_latin = ["darnitsa", "darnitsia", "kaptopres-darnitsia", "kaptopres-darnitsa"]
    
    found_items = []
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã (–¥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏) –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    if 'line_clusters_original' in locals():
        for i, cluster in enumerate(line_clusters_original):
            original_text_lower = cluster.text.lower()
            # –ò—â–µ–º –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
            if any(term in original_text_lower for term in search_terms_cyrillic):
                if i < len(line_items):
                    found_items.append((i, line_items[i], cluster.text))
    
    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ —Ç–æ–≤–∞—Ä–æ–≤ (–¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
    for i, item in enumerate(line_items):
        name_lower = item.get('name', '').lower()
        if any(term in name_lower for term in search_terms_latin):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –ª–∏ —É–∂–µ —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä
            if not any(idx == i for idx, _, _ in found_items):
                original_text = original_texts.get(i, item.get('name', ''))
                found_items.append((i, item, original_text))
    
    if found_items:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(found_items)} –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ '–î–∞—Ä–Ω–∏—Ü—è':")
        for idx, item, original_text in found_items:
            price_uah = item.get('price', 0) / 100 if item.get('price') else 0
            normalized_name = item.get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            print(f"  {idx+1}. {normalized_name}")
            if original_text != normalized_name:
                print(f"      (–æ—Ä–∏–≥–∏–Ω–∞–ª: {original_text})")
            print(f"      –¶–µ–Ω–∞: {price_uah:.2f} –≥—Ä–Ω")
    else:
        print("‚ùå –ü—Ä–µ–ø–∞—Ä–∞—Ç—ã '–î–∞—Ä–Ω–∏—Ü—è' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("   –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:")
        print(f"   - –ö–∏—Ä–∏–ª–ª–∏—Ü–∞: {', '.join(search_terms_cyrillic)}")
        print(f"   - –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è: {', '.join(search_terms_latin)}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ JSON
    output_file = project_root / "scripts" / "ocr_result.json"
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è JSON
        payload_for_json = json.loads(json.dumps(structured_payload, default=str))
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(payload_for_json, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ –ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON: {e}")
    
    print_section("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û", "=")
    
    return 0


if __name__ == "__main__":
    import asyncio
    sys.exit(asyncio.run(main()))

